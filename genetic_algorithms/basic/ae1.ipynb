{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ae1 import BaseGenetic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square function\n",
    "\n",
    "$f(x) = x_1^2 + x_2^2 + 2x_3^2$\n",
    "\n",
    "- Global minimum: $f(0) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_square(x: np.ndarray) -> float:\n",
    "    return x[0]**2 + x[1]**2 + 2 * x[2]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_square = BaseGenetic(\n",
    "    input_dim=3, population_size=100, loss_fn=f_square, random_state=33, init_interval_radius=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 done! Current loss value: 57958.611781422835\n",
      "Epoch 40 done! Current loss value: 44457.115842851425\n",
      "Epoch 60 done! Current loss value: 30938.934809323513\n",
      "Epoch 80 done! Current loss value: 19796.378235386568\n",
      "Epoch 100 done! Current loss value: 11526.631068556411\n",
      "Epoch 120 done! Current loss value: 5117.421827102339\n",
      "Epoch 140 done! Current loss value: 1327.3324453026885\n",
      "Epoch 160 done! Current loss value: 0.9919010257742515\n",
      "Epoch 180 done! Current loss value: 0.018479067645112143\n",
      "Epoch 200 done! Current loss value: 0.018479067645112143\n",
      "Epoch 220 done! Current loss value: 0.003233161586803739\n",
      "Epoch 240 done! Current loss value: 0.003233161586803739\n",
      "Epoch 260 done! Current loss value: 0.003233161586803739\n",
      "Epoch 280 done! Current loss value: 0.003233161586803739\n",
      "Epoch 300 done! Current loss value: 0.003233161586803739\n"
     ]
    }
   ],
   "source": [
    "gen_square.train(epochs=300, verbosity_period=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-dimensional Rastrigin function\n",
    "\n",
    "$f(x) = 50 + \\sum_{i=1}^{n} [x_i^2 - 10cos(2\\pi x_i)]$\n",
    "\n",
    "- Global minimum: $f(0) = 0$\n",
    "- Constraints: $x_i \\in [-5.12, 5.12]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rastrigin(x: np.ndarray) -> float:\n",
    "    if any(np.abs(x) > 5.12):\n",
    "        # penalty for not meeting the constraints\n",
    "        return 9999999999999\n",
    "    rsum = np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "    return 50 + rsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_rastrigin = BaseGenetic(\n",
    "    input_dim=3, population_size=500, loss_fn=f_rastrigin, random_state=33, init_interval_radius=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 done! Current loss value: 20.669460609636538\n",
      "Epoch 20 done! Current loss value: 20.669460609636538\n",
      "Epoch 30 done! Current loss value: 20.669460609636538\n",
      "Epoch 40 done! Current loss value: 20.669460609636538\n",
      "Epoch 50 done! Current loss value: 20.669460609636538\n",
      "Epoch 60 done! Current loss value: 20.669460609636538\n",
      "Epoch 70 done! Current loss value: 20.669460609636538\n",
      "Epoch 80 done! Current loss value: 20.669460609636538\n",
      "Epoch 90 done! Current loss value: 20.669460609636538\n",
      "Epoch 100 done! Current loss value: 20.669460609636538\n",
      "Epoch 110 done! Current loss value: 20.669460609636538\n",
      "Epoch 120 done! Current loss value: 20.669460609636538\n",
      "Epoch 130 done! Current loss value: 20.669460609636538\n",
      "Epoch 140 done! Current loss value: 20.669460609636538\n",
      "Epoch 150 done! Current loss value: 20.669460609636538\n",
      "Epoch 160 done! Current loss value: 20.669460609636538\n",
      "Epoch 170 done! Current loss value: 20.669460609636538\n",
      "Epoch 180 done! Current loss value: 20.669460609636538\n",
      "Epoch 190 done! Current loss value: 20.12192901862997\n",
      "Epoch 200 done! Current loss value: 20.12192901862997\n",
      "Epoch 210 done! Current loss value: 20.12192901862997\n",
      "Epoch 220 done! Current loss value: 20.12192901862997\n",
      "Epoch 230 done! Current loss value: 20.12192901862997\n",
      "Epoch 240 done! Current loss value: 20.12192901862997\n",
      "Epoch 250 done! Current loss value: 20.12192901862997\n",
      "Epoch 260 done! Current loss value: 20.12192901862997\n",
      "Epoch 270 done! Current loss value: 20.12192901862997\n",
      "Epoch 280 done! Current loss value: 20.12192901862997\n",
      "Epoch 290 done! Current loss value: 20.12192901862997\n",
      "Epoch 300 done! Current loss value: 20.12192901862997\n",
      "Epoch 310 done! Current loss value: 20.12192901862997\n",
      "Epoch 320 done! Current loss value: 20.12192901862997\n",
      "Epoch 330 done! Current loss value: 20.12192901862997\n",
      "Epoch 340 done! Current loss value: 20.12192901862997\n",
      "Epoch 350 done! Current loss value: 20.12192901862997\n",
      "Epoch 360 done! Current loss value: 20.12192901862997\n",
      "Epoch 370 done! Current loss value: 20.12192901862997\n",
      "Epoch 380 done! Current loss value: 20.12192901862997\n",
      "Epoch 390 done! Current loss value: 20.12192901862997\n",
      "Epoch 400 done! Current loss value: 20.12192901862997\n",
      "Epoch 410 done! Current loss value: 20.12192901862997\n",
      "Epoch 420 done! Current loss value: 20.12192901862997\n",
      "Epoch 430 done! Current loss value: 20.12192901862997\n",
      "Epoch 440 done! Current loss value: 20.12192901862997\n",
      "Epoch 450 done! Current loss value: 20.12192901862997\n",
      "Epoch 460 done! Current loss value: 20.12192901862997\n",
      "Epoch 470 done! Current loss value: 20.12192901862997\n",
      "Epoch 480 done! Current loss value: 20.12192901862997\n",
      "Epoch 490 done! Current loss value: 20.12192901862997\n",
      "Epoch 500 done! Current loss value: 20.12192901862997\n",
      "Epoch 510 done! Current loss value: 20.12192901862997\n",
      "Epoch 520 done! Current loss value: 20.12192901862997\n",
      "Epoch 530 done! Current loss value: 20.12192901862997\n",
      "Epoch 540 done! Current loss value: 20.12192901862997\n",
      "Epoch 550 done! Current loss value: 20.12192901862997\n",
      "Epoch 560 done! Current loss value: 20.12192901862997\n",
      "Epoch 570 done! Current loss value: 20.12192901862997\n",
      "Epoch 580 done! Current loss value: 20.12192901862997\n",
      "Epoch 590 done! Current loss value: 20.12192901862997\n",
      "Epoch 600 done! Current loss value: 20.12192901862997\n",
      "Epoch 610 done! Current loss value: 20.12192901862997\n",
      "Epoch 620 done! Current loss value: 20.12192901862997\n",
      "Epoch 630 done! Current loss value: 20.12192901862997\n",
      "Epoch 640 done! Current loss value: 20.12192901862997\n",
      "Epoch 650 done! Current loss value: 20.12192901862997\n",
      "Epoch 660 done! Current loss value: 20.12192901862997\n",
      "Epoch 670 done! Current loss value: 20.12192901862997\n",
      "Epoch 680 done! Current loss value: 20.12192901862997\n",
      "Epoch 690 done! Current loss value: 20.12192901862997\n",
      "Epoch 700 done! Current loss value: 20.12192901862997\n",
      "Epoch 710 done! Current loss value: 20.12192901862997\n",
      "Epoch 720 done! Current loss value: 20.12192901862997\n",
      "Epoch 730 done! Current loss value: 20.12192901862997\n",
      "Epoch 740 done! Current loss value: 20.12192901862997\n",
      "Epoch 750 done! Current loss value: 20.12192901862997\n",
      "Epoch 760 done! Current loss value: 20.12192901862997\n",
      "Epoch 770 done! Current loss value: 20.12192901862997\n",
      "Epoch 780 done! Current loss value: 20.12192901862997\n",
      "Epoch 790 done! Current loss value: 20.12192901862997\n",
      "Epoch 800 done! Current loss value: 20.12192901862997\n",
      "Epoch 810 done! Current loss value: 20.12192901862997\n",
      "Epoch 820 done! Current loss value: 20.12192901862997\n",
      "Epoch 830 done! Current loss value: 20.12192901862997\n",
      "Epoch 840 done! Current loss value: 20.12192901862997\n",
      "Epoch 850 done! Current loss value: 20.12192901862997\n",
      "Epoch 860 done! Current loss value: 20.12192901862997\n",
      "Epoch 870 done! Current loss value: 20.12192901862997\n",
      "Epoch 880 done! Current loss value: 20.12192901862997\n",
      "Epoch 890 done! Current loss value: 20.12192901862997\n",
      "Epoch 900 done! Current loss value: 20.12192901862997\n",
      "Epoch 910 done! Current loss value: 20.12192901862997\n",
      "Epoch 920 done! Current loss value: 20.12192901862997\n",
      "Epoch 930 done! Current loss value: 20.12192901862997\n",
      "Epoch 940 done! Current loss value: 20.12192901862997\n",
      "Epoch 950 done! Current loss value: 20.12192901862997\n",
      "Epoch 960 done! Current loss value: 20.12192901862997\n",
      "Epoch 970 done! Current loss value: 20.12192901862997\n",
      "Epoch 980 done! Current loss value: 20.12192901862997\n",
      "Epoch 990 done! Current loss value: 20.12192901862997\n",
      "Epoch 1000 done! Current loss value: 20.12192901862997\n"
     ]
    }
   ],
   "source": [
    "gen_rastrigin.train(epochs=1000, verbosity_period=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
